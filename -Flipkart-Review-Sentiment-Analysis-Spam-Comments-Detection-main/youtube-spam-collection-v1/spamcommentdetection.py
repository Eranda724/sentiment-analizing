# -*- coding: utf-8 -*-
"""SpamCommentDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/180nLdwxp2avi51hzUtjyT2KW-MVga2Tb
"""

import pandas as pd
import numpy as np

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import BernoulliNB

from google.colab import files
uploaded = files.upload()

#0=not spam
#1=spam

data = pd.read_csv('Youtube01-Psy.csv')
print(data.shape)
data.head()

#split only content and class columns
data = data[["CONTENT","CLASS"]]
data.sample(5)

#map the values as indicated 0 (not spam) and 1 (spam) comments
data["CLASS"] = data["CLASS"].map({0:"not spam",1:"spam"})
print(data.head(5))

dt = data.isnull().sum()
print(dt)

x=np.array(data["CONTENT"])
y=np.array(data["CLASS"])

cv = CountVectorizer()
X = cv.fit_transform(x) #to fit the dimensions of x
xtrain,xtest,ytrain,ytest = train_test_split(X,y,test_size=0.2,random_state=42)

model = BernoulliNB()
model.fit(xtrain,ytrain)

print(model.score(xtest,ytest))

#validate the trained model
sample="plz check out fablife / welcome to fablife for diys and challenges so plz  subscribe thx!ï»¿"
data = cv.transform([sample]).toarray() #string convert to array
print(model.predict(data))

sample="Nice"
data = cv.transform([sample]).toarray() #string convert to array
print(model.predict(data))